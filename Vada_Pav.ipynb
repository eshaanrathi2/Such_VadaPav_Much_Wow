{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential, load_model, Model\n",
    "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras import backend as K\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/job:localhost/replica:0/task:0/device:GPU:0']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checks if keras using GPU\n",
    "K.tensorflow_backend._get_available_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_width, img_height = 224, 224  #150\n",
    "input_shape = (img_width, img_height, 3)\n",
    "\n",
    "train_data = r'C:\\Users\\RS_Vulcan\\Documents\\vada_pav_data\\train'\n",
    "valid_data = r'C:\\Users\\RS_Vulcan\\Documents\\vada_pav_data\\valid'\n",
    "\n",
    "train_samples = 536\n",
    "valid_samples = 106\n",
    "epochs = 50\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "## -----------------------MODEL-3---------------------------------------------------------------------\n",
    "\n",
    "def conv_model(input_shape):\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(16, (3, 3), activation='relu', input_shape=input_shape))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1, activation = 'sigmoid'))\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "## -----------------------MODEL-4---------------------------------------------------------------------\n",
    "\n",
    "def mobilenet(input_shape):\n",
    "    from keras.applications import MobileNet\n",
    "\n",
    "    base_model=MobileNet(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "\n",
    "    x=base_model.output\n",
    "    x=GlobalAveragePooling2D()(x)\n",
    "    x=Dense(1024,activation='relu')(x)\n",
    "    x=Dense(1024,activation='relu')(x)\n",
    "    x=Dense(512,activation='relu')(x)\n",
    "    preds=Dense(1,activation='sigmoid')(x)\n",
    "    model=Model(inputs=base_model.input,outputs=preds)\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = conv_model(input_shape)\n",
    "model = mobilenet(input_shape)\n",
    "\n",
    "# freezing layers 1 to 20 and training remaining layers\n",
    "# use for mobilenet(), comment when using conv_model()\n",
    "for layer in model.layers[:20]:\n",
    "    layer.trainable=False\n",
    "for layer in model.layers[20:]:\n",
    "    layer.trainable=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rotation_range=15,\n",
    "                               rescale=1./ 255,\n",
    "                               width_shift_range=0.1,\n",
    "                               height_shift_range=0.1,\n",
    "                               shear_range=0.01,\n",
    "                               zoom_range=[0.9, 1.25],\n",
    "                               horizontal_flip=True,\n",
    "                               vertical_flip=False,\n",
    "                               fill_mode='nearest',\n",
    "                               data_format='channels_last',\n",
    "                               brightness_range=[0.5, 1.5])\n",
    "    \n",
    "\n",
    "valid_datagen = ImageDataGenerator(rotation_range=15,\n",
    "                               rescale=1./ 255,\n",
    "                               width_shift_range=0.1,\n",
    "                               height_shift_range=0.1,\n",
    "                               shear_range=0.01,\n",
    "                               zoom_range=[0.9, 1.25],\n",
    "                               horizontal_flip=True,\n",
    "                               vertical_flip=False,\n",
    "                               fill_mode='nearest',\n",
    "                               data_format='channels_last',\n",
    "                               brightness_range=[0.5, 1.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 536 images belonging to 2 classes.\n",
      "Found 106 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(train_data,\n",
    "                                                    target_size=(img_width, img_height),\n",
    "                                                    batch_size=batch_size,\n",
    "                                                    class_mode='binary')\n",
    "    \n",
    "valid_generator = valid_datagen.flow_from_directory(valid_data,\n",
    "                                                    target_size=(img_width, img_height),\n",
    "                                                    batch_size=batch_size,\n",
    "                                                    class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit_generator(train_generator,\n",
    "                    steps_per_epoch=train_samples // batch_size, #50\n",
    "                    epochs=epochs,\n",
    "                    validation_data=valid_generator,\n",
    "                    validation_steps= valid_samples // batch_size)  #50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model and weights\n",
    "model.save_weights(r'C:\\Users\\RS_Vulcan\\Documents\\vada_pav_data\\models\\model_4_weights.h5')\n",
    "model.save(r'C:\\Users\\RS_Vulcan\\Documents\\vada_pav_data\\models\\model_4.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model and weights\n",
    "test_model = load_model('C:/Users/RS_Vulcan/Documents/vada_pav_data/models/model_4.h5')\n",
    "test_model.load_weights('C:/Users/RS_Vulcan/Documents/vada_pav_data/models/model_4_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = r'C:\\Users\\RS_Vulcan\\Documents\\vada_pav_data\\test'\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "img_width, img_height = 224, 224  #224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_generator = test_datagen.flow_from_directory(test_data,\n",
    "#                                                 shuffle=False,\n",
    "#                                                 target_size=(img_width, img_height),\n",
    "#                                                 batch_size=1,\n",
    "#                                                 class_mode=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_generator.reset()\n",
    "# pred = model.predict_generator(test_generator, verbose=1)\n",
    "# pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "columns = 5\n",
    "text_labels = []\n",
    "plt.figure(figsize=(30,30))\n",
    "for batch in test_datagen.flow_from_directory(\n",
    "    test_data,\n",
    "    shuffle=True,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=1,\n",
    "    class_mode=None):\n",
    "    pred = test_model.predict(batch)\n",
    "    if pred > 0.5:\n",
    "        text_labels.append('a Vada Pav')\n",
    "    else:\n",
    "        text_labels.append('not a Vada Pav')\n",
    "    plt.subplot(5 , columns, i + 1)\n",
    "    plt.title('This is ' + text_labels[i])\n",
    "    imgplot = plt.imshow(batch[0])\n",
    "    i += 1\n",
    "#     plt.show()\n",
    "    if i % 25 == 0:\n",
    "        break\n",
    "# plt.subplots_adjust(left=0.125, bottom=0.1, right=0.9 , top=0.9, wspace=0.7, hspace=0.7)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file = r'C:\\Users\\RS_Vulcan\\Documents\\vada_pav_data\\test\\test\\10.jpg'\n",
    "# from keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
    "# img_width, img_height = 150, 150  #224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = load_img(file, target_size=(img_width, img_height))\n",
    "# x = img_to_array(x)\n",
    "# x = np.expand_dims(x, axis=0)\n",
    "# array = test_model.predict(x)\n",
    "# result = array[0]\n",
    "# # answer = np.argmax(result)\n",
    "# if result == [0.]:\n",
    "#     print('Not a Vada Pav')\n",
    "# else:\n",
    "#     print('Vada Pav')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
